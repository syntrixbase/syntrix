# Metrics Collection Architecture

- Date: 2026-01-18
- Status: Draft
- Scope: In-process metrics instrumentation and Prometheus exposition
- Owner: TBD (Observability)

## Why

The existing monitoring design documents (000-002) define the overall observability strategy. This document focuses specifically on **in-process metrics collection** - the foundation that enables all downstream monitoring capabilities.

Current state:
- Puller has Prometheus metrics (`internal/puller/metrics/`)
- Trigger has a Metrics interface but only NoopMetrics implementation
- Gateway, Query, Indexer, Streamer have no metrics

Goals:
- Provide visibility into service health without external dependencies
- Enable Prometheus scraping via `/metrics` endpoint
- Establish consistent patterns for adding metrics across services
- Support both standalone and distributed deployment modes

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                        Syntrix Process                          │
│                                                                 │
│  ┌──────────┐  ┌───────┐  ┌─────────┐  ┌──────────┐  ┌────────┐│
│  │ Gateway  │  │ Query │  │ Indexer │  │ Streamer │  │Trigger ││
│  │ Metrics  │  │Metrics│  │ Metrics │  │ Metrics  │  │Metrics ││
│  └────┬─────┘  └───┬───┘  └────┬────┘  └────┬─────┘  └───┬────┘│
│       │            │           │            │            │      │
│       └────────────┴───────────┴────────────┴────────────┘      │
│                              │                                  │
│                    ┌─────────▼──────────┐                       │
│                    │  Metrics Registry  │                       │
│                    │  (Custom Registry) │                       │
│                    └─────────┬──────────┘                       │
│                              │                                  │
│                    ┌─────────▼──────────┐                       │
│                    │ HTTP Server :8080  │                       │
│                    │   GET /metrics     │                       │
│                    └────────────────────┘                       │
└─────────────────────────────────────────────────────────────────┘
                               │
                               ▼ Prometheus scrape
                    ┌────────────────────┐
                    │     Prometheus     │
                    └─────────┬──────────┘
                              │
                              ▼
                    ┌────────────────────┐
                    │      Grafana       │
                    └────────────────────┘
```

## Design Decisions

### Why Custom Registry (Not Global)

**Decision**: Use a custom `prometheus.Registry` instead of the default global registry.

**Why**:
- Avoids conflicts from multiple `init()` registrations
- Easier to test (inject mock registry)
- Cleaner separation of application metrics vs Go runtime metrics
- Can selectively include/exclude collectors

**How**:
```go
// Create custom registry
registry := prometheus.NewRegistry()

// Add standard collectors
registry.MustRegister(collectors.NewGoCollector())
registry.MustRegister(collectors.NewProcessCollector(collectors.ProcessCollectorOpts{}))

// Add application metrics
registry.MustRegister(gatewayMetrics)
```

### Why Reuse Existing HTTP Server

**Decision**: Mount `/metrics` on the existing Gateway HTTP server (port 8080).

**Why**:
- No additional port to manage
- Simpler deployment and firewall configuration
- Consistent with "splittable monolith" design
- Authentication can be applied uniformly (future)

**Trade-off**: If Gateway is not running, metrics are unavailable. This is acceptable because:
- In standalone mode, Gateway always runs
- In distributed mode, each service can expose its own `/metrics`

### Why Histogram Over Summary

**Decision**: Use `Histogram` for latency metrics instead of `Summary`.

**Why**:
- Histograms are aggregatable across instances
- PromQL can calculate any percentile from histograms
- Consistent with OpenTelemetry recommendations
- Already used in existing Puller metrics

**Bucket configuration**:
```go
// HTTP request latency buckets (seconds)
// Covers 5ms to 10s range
[]float64{0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10}
```

## Component Design

### Package Structure

```
internal/core/metrics/
├── registry.go      # Global registry, initialization, /metrics handler
├── config.go        # Configuration struct
├── middleware.go    # HTTP middleware for Gateway
├── gateway.go       # Gateway-specific metrics
├── query.go         # Query service metrics
├── indexer.go       # Indexer service metrics
├── streamer.go      # Streamer service metrics
├── trigger.go       # Trigger metrics (implements types.Metrics interface)
└── labels.go        # Common label definitions, validation
```

### Core Metrics Interface

```go
// registry.go

// Registry holds the Prometheus registry and provides registration helpers
type Registry struct {
    prometheus.Registerer
    prometheus.Gatherer
}

// NewRegistry creates a new metrics registry with standard collectors
func NewRegistry() *Registry

// Handler returns an HTTP handler for /metrics endpoint
func (r *Registry) Handler() http.Handler
```

### Metric Naming Convention

Follow Prometheus naming best practices:

```
{namespace}_{subsystem}_{name}_{unit}

Examples:
- syntrix_gateway_requests_total
- syntrix_gateway_request_duration_seconds
- syntrix_query_operations_total
- syntrix_indexer_documents_indexed
- syntrix_streamer_active_subscriptions
```

### Label Guidelines

**Required labels** (enforced at collection):
- `database` - Database identifier (when applicable)

**Standard labels**:
- `method` - HTTP method (GET, POST, etc.)
- `path` - Normalized path pattern (e.g., `/api/v1/{collection}`)
- `status` - HTTP status code or status class (2xx, 4xx, 5xx)
- `operation` - Operation type (create, read, update, delete, query)

**Cardinality guardrails**:
- Never use document IDs as labels
- Never use user IDs as labels
- Normalize paths to patterns (replace IDs with placeholders)
- Max 10 unique values per label recommended

## Service Metrics Specification

### Gateway Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `syntrix_gateway_requests_total` | Counter | method, path, status | Total HTTP requests |
| `syntrix_gateway_request_duration_seconds` | Histogram | method, path | Request latency |
| `syntrix_gateway_request_size_bytes` | Histogram | method, path | Request body size |
| `syntrix_gateway_response_size_bytes` | Histogram | method, path | Response body size |
| `syntrix_gateway_active_connections` | Gauge | protocol | Active WebSocket/SSE connections |

### Query Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `syntrix_query_operations_total` | Counter | operation, database, status | Query operations |
| `syntrix_query_duration_seconds` | Histogram | operation, database | Query execution time |
| `syntrix_query_documents_scanned` | Histogram | database | Documents scanned per query |
| `syntrix_query_documents_returned` | Histogram | database | Documents returned per query |

### Indexer Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `syntrix_indexer_documents_total` | Gauge | database, index | Indexed document count |
| `syntrix_indexer_events_processed_total` | Counter | database, type | Events processed from Puller |
| `syntrix_indexer_index_size_bytes` | Gauge | database, index | Index memory size |
| `syntrix_indexer_query_duration_seconds` | Histogram | database | Index lookup time |

### Streamer Metrics

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `syntrix_streamer_subscriptions_active` | Gauge | database | Active subscriptions |
| `syntrix_streamer_events_delivered_total` | Counter | database | Events pushed to clients |
| `syntrix_streamer_events_filtered_total` | Counter | database | Events filtered out |
| `syntrix_streamer_delivery_latency_seconds` | Histogram | database | Event delivery latency |

### Puller Metrics (Existing)

Already implemented in `internal/puller/metrics/`. Will be migrated to use shared registry.

### Trigger Metrics

Implements the existing `types.Metrics` interface with Prometheus backend:

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `syntrix_trigger_publish_total` | Counter | database, collection, status | Events published to NATS |
| `syntrix_trigger_publish_duration_seconds` | Histogram | database | Publish latency |
| `syntrix_trigger_consume_total` | Counter | database, collection, status | Events consumed from NATS |
| `syntrix_trigger_consume_duration_seconds` | Histogram | database | Consume latency |
| `syntrix_trigger_delivery_total` | Counter | database, collection, status | Webhook deliveries |
| `syntrix_trigger_delivery_duration_seconds` | Histogram | database | Delivery latency |
| `syntrix_trigger_delivery_retries_total` | Counter | database, collection | Delivery retries |

## Configuration

```yaml
# config.yml
metrics:
  enabled: true           # Enable metrics collection
  path: "/metrics"        # HTTP endpoint path
  namespace: "syntrix"    # Metric name prefix
  enableGoMetrics: true   # Include go_* metrics
  enableProcessMetrics: true  # Include process_* metrics
```

```go
// config.go
type Config struct {
    Enabled              bool   `yaml:"enabled" default:"true"`
    Path                 string `yaml:"path" default:"/metrics"`
    Namespace            string `yaml:"namespace" default:"syntrix"`
    EnableGoMetrics      bool   `yaml:"enableGoMetrics" default:"true"`
    EnableProcessMetrics bool   `yaml:"enableProcessMetrics" default:"true"`
}
```

## Integration Points

### Service Manager Integration

```go
// internal/services/manager_init.go

func (m *Manager) Init(ctx context.Context) error {
    // Initialize metrics registry
    metricsRegistry := metrics.NewRegistry(m.cfg.Metrics)

    // Create service-specific metrics
    gatewayMetrics := metrics.NewGatewayMetrics(metricsRegistry)
    triggerMetrics := metrics.NewTriggerMetrics(metricsRegistry)

    // Inject into services
    m.gateway = gateway.New(gatewayMetrics, ...)
    m.triggerService = trigger.New(triggerMetrics, ...)

    // Mount /metrics endpoint
    server.Default().RegisterHandler("GET", m.cfg.Metrics.Path, metricsRegistry.Handler())
}
```

### HTTP Middleware Integration

```go
// internal/gateway/rest/middleware.go

func MetricsMiddleware(metrics *metrics.GatewayMetrics) func(http.Handler) http.Handler {
    return func(next http.Handler) http.Handler {
        return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
            start := time.Now()

            // Wrap response writer to capture status
            wrapped := &statusResponseWriter{ResponseWriter: w, status: 200}

            next.ServeHTTP(wrapped, r)

            // Record metrics
            duration := time.Since(start).Seconds()
            path := normalizePath(r.URL.Path)

            metrics.RequestsTotal.WithLabelValues(r.Method, path, strconv.Itoa(wrapped.status)).Inc()
            metrics.RequestDuration.WithLabelValues(r.Method, path).Observe(duration)
        })
    }
}
```

## Implementation Plan

### Phase 1: Foundation (Current)

1. Create `internal/core/metrics/` package
2. Implement `Registry` with custom prometheus.Registry
3. Mount `/metrics` endpoint on HTTP server
4. Add configuration support

### Phase 2: Gateway Metrics

1. Implement Gateway metrics (requests, latency, connections)
2. Create HTTP middleware for automatic instrumentation
3. Normalize path patterns for low-cardinality labels

### Phase 3: Service Metrics

1. Implement Query, Indexer, Streamer metrics
2. Migrate Puller metrics to shared registry
3. Implement Trigger metrics (replace NoopMetrics)

### Phase 4: Polish

1. Add comprehensive unit tests
2. Update Grafana dashboards with new metrics
3. Document metric meanings in README

## Testing Strategy

### Unit Tests

- Test metric registration without conflicts
- Test label cardinality validation
- Test HTTP handler output format

### Integration Tests

- Verify `/metrics` endpoint returns expected format
- Verify metrics increment correctly during operations
- Test with Prometheus scrape simulation

## Open Questions

1. Should we support pushing metrics to Prometheus Pushgateway for batch jobs?
2. Do we need per-database metric isolation (separate registries)?
3. Should `/metrics` require authentication in production?

## References

- [Prometheus Naming Best Practices](https://prometheus.io/docs/practices/naming/)
- [Prometheus Go Client Library](https://github.com/prometheus/client_golang)
- [OpenTelemetry Metrics Semantic Conventions](https://opentelemetry.io/docs/specs/semconv/http/http-metrics/)
