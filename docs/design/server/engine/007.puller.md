# Engine Integration with Puller Service

Date: December 29, 2025
Status: Updated - References Standalone Puller Service
Scope: How Query Engine consumes change events from the standalone Puller service for index updates.

**IMPORTANT**: The Puller component has been promoted to a standalone service. See [Puller Service Architecture](../puller/001.architecture.md) for the complete design.

This document describes how the Query Engine integrates with the Puller service for index updates.

## Architecture Overview

```
MongoDB Change Stream
    ↓
Puller Service (Standalone)
    ↓
NATS JetStream
    ↓
Query Engine Index Consumer
    ↓
Index Updates
```

## Engine's Responsibilities
- Subscribe to relevant NATS JetStream subjects from Puller
- Consume change events for index updates
- Maintain per-collection checkpoints for rebuild decisions
- Detect lag/gaps and trigger index rebuild when needed

## Canonical Event Schema

**IMPORTANT**: The canonical event schema is defined in [Puller Service Architecture](../puller/001.architecture.md). All field names and formats below match that definition.

### Event Schema from Puller

Events from Puller follow this JSON schema:

```json
{
  "eventId": "unique-event-id",
  "tenant": "tenant-id",
  "collection": "collection-name",
  "documentId": "document-id",
  "operationType": "insert",
  "fullDocument": { ... },
  "updateDescription": {
    "updatedFields": { ... },
    "removedFields": ["field1"],
    "truncatedArrays": []
  },
  "clusterTime": { "T": 1234567890, "I": 1 },
  "txnNumber": null,
  "timestamp": 1234567890000
}
```

### Field Reference

| Field | Type | Description |
|-------|------|-------------|
| `eventId` | string | Unique event identifier for deduplication |
| `tenant` | string | Tenant ID (NOT "tenantId") |
| `collection` | string | Collection name |
| `documentId` | string | Document ID (NOT "documentKey") |
| `operationType` | string | lowercase: "insert", "update", "replace", "delete" |
| `fullDocument` | object | Complete document (for insert/update/replace) |
| `updateDescription` | object | Delta for updates (updatedFields, removedFields, truncatedArrays) |
| `clusterTime` | object | MongoDB cluster timestamp {T, I} |
| `txnNumber` | int64 | Transaction number (if in transaction) |
| `timestamp` | int64 | Unix milliseconds |

## Integration Pattern

### Consuming from Puller via JetStream

```go
type IndexEventConsumer struct {
    js           nats.JetStreamContext
    consumerName string
    collections  []string  // Collections this engine instance cares about
}

func (c *IndexEventConsumer) Subscribe(ctx context.Context) error {
    // Subscribe to Puller events for specific collections
    // Subject pattern: puller.events.{collection}.{partition}

    for _, collection := range c.collections {
        subject := fmt.Sprintf("puller.events.%s.>", collection)

        _, err := c.js.Subscribe(subject, c.handleIndexUpdate,
            nats.ManualAck(),
            nats.Durable(c.consumerName),
            nats.DeliverAll())

        if err != nil {
            return err
        }
    }
    return nil
}

// PullerEvent matches the canonical schema from Task 016
type PullerEvent struct {
    EventID      string                 `json:"eventId"`
    TenantID     string                 `json:"tenant"`
    Collection   string                 `json:"collection"`
    DocumentID   string                 `json:"documentId"`
    Type         string                 `json:"operationType"`
    FullDocument map[string]interface{} `json:"fullDocument,omitempty"`
    UpdateDesc   *UpdateDescription     `json:"updateDescription,omitempty"`
    ClusterTime  struct {
        T uint32 `json:"T"`
        I uint32 `json:"I"`
    } `json:"clusterTime"`
    TxnNumber *int64 `json:"txnNumber,omitempty"`
    Timestamp int64  `json:"timestamp"`
}

type UpdateDescription struct {
    UpdatedFields   map[string]interface{} `json:"updatedFields,omitempty"`
    RemovedFields   []string               `json:"removedFields,omitempty"`
    TruncatedArrays []TruncatedArray       `json:"truncatedArrays,omitempty"`
}

type TruncatedArray struct {
    Field   string `json:"field"`
    NewSize int    `json:"newSize"`
}

func (c *IndexEventConsumer) handleIndexUpdate(msg *nats.Msg) {
    // Decode event from Puller
    var evt PullerEvent
    if err := json.Unmarshal(msg.Data, &evt); err != nil {
        log.Error("Failed to unmarshal puller event: %v", err)
        msg.Nak()
        return
    }

    // Apply to index
    if err := c.index.Upsert(evt); err != nil {
        log.Error("Failed to apply index update: %v", err)
        msg.Nak()
        return
    }

    // Ack after successful application
    msg.Ack()
}
```

## Engine Consumer Configuration

```yaml
engine:
  index:
    puller:
      # NATS connection
      nats_urls:
        - nats://localhost:4222

      # Consumer settings
      consumer_name: "engine-index-{instance-id}"
      ack_wait: 5s
      max_ack_pending: 100

      # Collections to subscribe to
      collections:
        - users
        - orders
        - products

      # Checkpoint settings (local to Engine)
      checkpoint_store: etcd  # or mongo
      checkpoint_interval: 1s

      # Rebuild triggers
      lag_thresholds:
        soft_warn: 30s       # Log warning
        hard_rebuild: 2m    # Trigger index rebuild
```

## Index Update Semantics

### At-Least-Once Delivery
- Puller publishes events to JetStream with persistence
- Engine consumes with manual acknowledgment
- Events may be delivered multiple times (on retry, reconnect, etc.)
- **Engine index apply must be idempotent**

### Idempotency Requirements

```go
func (idx *Index) Upsert(evt PullerEvent) error {
    // Check if this event is older than current indexed version
    current := idx.Get(evt.DocumentID)
    if current != nil && compareTimestamp(current.ClusterTime, evt.ClusterTime) >= 0 {
        // Skip older event (idempotent)
        return nil
    }

    // Apply update
    return idx.upsertDocument(evt)
}

// compareTimestamp compares MongoDB timestamps (T=seconds, I=increment)
func compareTimestamp(a, b ClusterTime) int {
    if a.T != b.T {
        if a.T < b.T {
            return -1
        }
        return 1
    }
    if a.I < b.I {
        return -1
    }
    if a.I > b.I {
        return 1
    }
    return 0
}
```

### Ordering Guarantees
- Puller guarantees per-partition ordering (via subject partitioning)
- Engine consumer should subscribe with single consumer per partition
- Multiple Engine instances can consume different partitions for scalability

## Lag Detection and Rebuild Triggers

### Monitoring Lag

```go
type LagMonitor struct {
    checkpointStore CheckpointStore
    jetstream       nats.JetStreamContext
}

func (m *LagMonitor) CheckLag(collection string) (time.Duration, error) {
    // Get Engine's last processed checkpoint
    checkpoint := m.checkpointStore.Get(collection)

    // Get latest available event from JetStream
    streamInfo := m.jetstream.StreamInfo("PULLER_EVENTS")

    // Calculate lag
    lag := calculateTimeLag(checkpoint, streamInfo.State.LastSeq)
    return lag, nil
}
```

### Rebuild Triggers

When lag exceeds thresholds:
1. **Soft Lag (30s)**: Log warning, emit metrics
2. **Hard Lag (2m)**: Trigger index rebuild from scratch

Rebuild process:
1. Stop consuming from JetStream temporarily
2. Query Engine scans MongoDB directly (via Data layer)
3. Rebuild index from current state
4. Resume JetStream consumption from latest

## Benefits of Using Standalone Puller

1. **Reduced MongoDB Load**: Single change stream connection (in Puller) instead of one per Engine instance
2. **Independent Scaling**: Puller and Engine can scale independently
3. **Shared Infrastructure**: Other services (Streamer, Trigger) also consume from same Puller
4. **Simplified Engine**: Engine no longer manages MongoDB connections or checkpoints at storage level
5. **Better Observability**: Centralized monitoring in Puller service

## Migration from Direct MongoDB Connection

For existing deployments:
1. Deploy Puller service
2. Configure Engine to subscribe to Puller's JetStream subjects
3. Trigger initial index rebuild to sync state
4. Remove direct MongoDB change stream code from Engine
5. Verify lag metrics and performance

## References

- [Puller Service Architecture](../server/puller/001.architecture.md) - Complete Puller design
- [Query Engine Index Design](003.index.md) - Index structure and operations
- [Query Engine Architecture](001.architecture.md) - Overall Engine architecture
