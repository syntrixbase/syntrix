# Core Pubsub Layer

## Overview (Why/How)

- **Why**: The trigger system currently has NATS JetStream publisher/consumer implementations tightly coupled to trigger-specific types (`DeliveryTask`, `Metrics`). This coupling prevents reuse and makes it harder to swap transport layers or test components in isolation.

- **How**: Extract a generic pubsub abstraction into `internal/core/pubsub/` that provides transport-agnostic interfaces. The trigger system (and future services) will use this abstraction, with NATS JetStream as the default implementation.

## Goals

1. **Reusability** - Other services can use the same pubsub infrastructure
2. **Testability** - Interfaces can be easily mocked without NATS dependencies
3. **Decoupling** - Business logic doesn't depend on transport implementation
4. **Flexibility** - Can swap NATS for other message brokers if needed

## Non-Goals

1. Multi-broker support in v1 (NATS-only initially)
2. Complex routing patterns (topic exchanges, etc.)
3. Exactly-once semantics (at-least-once is sufficient)

## Package Structure

```
internal/core/pubsub/
├── interfaces.go     # Core interfaces (Publisher, Consumer, Message)
├── options.go        # Configuration options
├── nats/             # NATS JetStream implementation
│   ├── publisher.go
│   ├── consumer.go
│   └── connection.go
└── testing/          # Test utilities and mocks
    └── mock.go
```

## Core Interfaces

### Message

```go
// Message represents a received message with acknowledgment controls.
type Message interface {
    Data() []byte
    Subject() string
    Ack() error
    Nak() error
    NakWithDelay(delay time.Duration) error
    Term() error
    Metadata() (MessageMetadata, error)
}

type MessageMetadata struct {
    NumDelivered uint64
    Timestamp    time.Time
    Subject      string
    Stream       string
    Consumer     string
}
```

### Publisher

```go
// Publisher publishes messages to a stream.
type Publisher interface {
    Publish(ctx context.Context, subject string, data []byte) error
    Close() error
}

type PublisherOptions struct {
    StreamName    string
    SubjectPrefix string
    OnPublish     func(subject string, err error, latency time.Duration)
}
```

### Consumer

```go
// Consumer consumes messages from a stream.
type Consumer interface {
    // Subscribe starts consuming messages and returns a channel.
    // The channel is closed when the context is cancelled or an error occurs.
    // Caller is responsible for calling Ack/Nak/Term on each message.
    Subscribe(ctx context.Context) (<-chan Message, error)
}

type ConsumerOptions struct {
    StreamName     string
    ConsumerName   string
    FilterSubject  string
    ChannelBufSize int
}
```

## Error Handling

### Publisher Errors

- Connection errors: Return error, let caller decide retry
- Stream not found: Auto-create stream (configurable)
- Timeout: Return error with context

### Consumer Errors

With the Subscribe pattern, error handling is the caller's responsibility:

- Caller receives messages from channel
- Caller processes and decides Ack/Nak/Term
- Caller implements retry logic as needed

Retry logic remains in the application-specific layer, not in core pubsub.

## Design Decisions

### 1. Raw Bytes vs Typed Messages

**Decision**: Use `[]byte` for message data, no serialization in core.

**Rationale**: Different consumers may use different serialization formats (JSON, protobuf, etc.). Core pubsub should be format-agnostic.

### 2. Connection Management

**Decision**: Accept `*nats.Conn` from caller, don't manage connections.

**Rationale**: Connections may be shared across multiple components. Caller (ServiceManager) owns the connection lifecycle.

### 3. Stream Creation

**Decision**: Auto-create streams with sensible defaults, allow override via options.

**Rationale**: Simplifies usage for common cases. Advanced users can pre-create streams with custom settings.

### 4. Metrics Hooks vs Interface

**Decision**: Use callback hook (`OnPublish`) for publisher metrics. Consumer metrics are handled by caller.

**Rationale**: More flexible - callers can map to their own metrics systems. With Subscribe pattern, caller has full control over message processing timing.

### 5. Subscribe Pattern vs Handler Pattern

**Decision**: Use Subscribe pattern (return channel) instead of Handler pattern (callback).

**Rationale**:
- Simpler core implementation - no internal worker pool management
- More flexible for callers - they control concurrency and worker pools
- Easier to test - just read from channel
- Caller can implement custom partitioning/ordering as needed

## Usage Pattern

```go
// Publisher side (e.g., Trigger Evaluator)
js, _ := natspubsub.NewJetStream(conn)
pub, _ := natspubsub.NewPublisher(js, pubsub.PublisherOptions{
    StreamName:    "TRIGGERS",
    SubjectPrefix: "TRIGGERS",
})
pub.Publish(ctx, "db1.users.doc123", jsonData)

// Consumer side (e.g., Trigger Delivery)
js, _ := natspubsub.NewJetStream(conn)
consumer, _ := natspubsub.NewConsumer(js, pubsub.ConsumerOptions{
    StreamName:    "TRIGGERS",
    ConsumerName:  "DeliveryWorker",
    FilterSubject: "TRIGGERS.>",
})

msgCh, _ := consumer.Subscribe(ctx)
for msg := range msgCh {
    // Process message
    if err := processMessage(msg); err != nil {
        msg.Nak()
    } else {
        msg.Ack()
    }
}
```

## Compatibility Notes

- Subject scheme remains: `<stream_name>.<database>.<collection>.<docKey>`
- Existing checkpoint/resume token logic stays in trigger layer
- NATS connection lifecycle managed by `ServiceManager`
