server:
  host: "localhost"
  http_port: 8080
  http_read_timeout: 10s
  http_write_timeout: 10s
  http_idle_timeout: 60s
  enable_cors: true

  grpc_port: 9000
  GRPCMaxConcurrent: 100

  ShutdownTimeout: 15s

storage:
  backends:
    default_mongo:
      type: mongo
      mongo:
        uri: "mongodb://localhost:27017"
        database_name: "syntrix"
    default_postgres:
      type: postgres
      postgres:
        dsn: "postgres://syntrix:syntrix@localhost:5432/syntrix?sslmode=disable"
        max_open_conns: 10
        max_idle_conns: 5
        conn_max_lifetime: 5m
  topology:
    document:
      strategy: single
      primary: default_mongo
      data_collection: documents
      sys_collection: sys
      soft_delete_retention: 720h # 30 days
    user:
      strategy: single
      primary: default_postgres
      collection: auth_users
    revocation:
      strategy: single
      primary: default_mongo
      collection: revocations

identity:
  authn:
    access_token_ttl: 15m
    refresh_token_ttl: 168h # 7 days
    auth_code_ttl: 2m
    private_key_file: "keys/auth_private.pem"
  authz:
    rules_path: "security_rules"
  admin:
    username: "syntrix"
    password: "changeme123456"  # Change this in production

gateway:
  query_service_url: "localhost:9000"
  streamer_service_url: "localhost:9000"
  realtime:
    transport: "both"
    per_message_deflate: true

query:
  indexer_addr: "localhost:9000"

trigger:
  nats_url: "nats://localhost:4222"
  rules_path: "triggers"
  worker_count: 32
  stream_name: "TRIGGERS"

puller:
  grpc:
    address: ":50051"
    max_connections: 100
    channel_size: 10000
  backends:
    - name: "default_mongo"
      collections: ["documents"]
  buffer:
    path: ".syntrix/data/puller/events"
    max_size: "10GiB"
    batch_size: 100
    batch_interval: 100ms
    queue_size: 10000
  consumer:
    catch_up_threshold: 100000
    coalesce_on_catch_up: true
  cleaner:
    interval: 1m
    retention: 1h
  bootstrap:
    mode: "from_now"
  metrics:
    port: 9090
    path: "/metrics"
  health:
    port: 8081
    path: "/health"

streamer:
  server:
    puller_addr: "localhost:9000"
    send_timeout: 5s
  client:
    streamer_addr: "localhost:9000"
    initial_backoff: 1s
    max_backoff: 30s
    backoff_multiplier: 2.0
    max_retries: 0
    heartbeat_interval: 30s
    activity_timeout: 90s

indexer:
  puller_addr: "localhost:9000"
  template_path: "index_templates"
  progress_path: "data/indexer/progress"
  consumer_id: "indexer"
  reconcile_interval: 5s
  storage_mode: "memory"
  store:
    path: "data/indexer/indexes.db"
    batch_size: 100
    batch_interval: 100ms
    queue_size: 10000
    block_cache_size: 134217728

# Logging configuration
logging:
  # Global log level: debug, info, warn, error
  level: "info"

  # Log format: text (human-readable) or json (machine-readable)
  format: "text"

  # Log directory (relative or absolute path)
  # Relative paths are resolved from the parent of the config directory
  # Default: "logs" (creates ./logs directory)
  dir: "logs"

  # File rotation settings
  rotation:
    # Maximum size in megabytes before rotation (default: 500)
    max_size: 500

    # Maximum number of old log files to retain (default: 10)
    max_backups: 5

    # Maximum days to retain old log files (default: 30)
    max_age: 14

    # Compress rotated files with gzip (default: true)
    compress: true

  # Console output (stdout) configuration
  console:
    enabled: true
    level: "info"    # Can override global level
    format: "text"   # text or json

  # Main file output configuration
  file:
    enabled: true
    level: "info"    # Can override global level
    format: "json"   # text or json

  # Async logging configuration (improves performance for high-throughput scenarios)
  async:
    # Enable async logging (default: false)
    # When enabled, log writes are non-blocking and batched for better throughput
    enabled: true

    # Buffer size for the async channel (default: 10000)
    # Higher values allow more logs to be buffered during traffic spikes
    buffer_size: 10000

    # Batch size for grouping writes (default: 100)
    # Logs are flushed when batch reaches this size or timeout occurs
    batch_size: 200

    # Flush timeout in milliseconds (default: 100)
    # Maximum time to wait before flushing a partial batch
    flush_timeout: 100

  # Log deduplication configuration (reduces repeated identical log messages)
  dedup:
    # Enable log deduplication (default: true)
    # Deduplicates logs based on level, message, and attributes (excluding timestamp)
    enabled: true

    # Batch size for deduplication (default: 100)
    # Logs are deduplicated and flushed when batch reaches this size
    batch_size: 100

    # Flush timeout in milliseconds (default: 1000)
    # Maximum time to wait before flushing deduplicated logs
    flush_timeout: 1000
